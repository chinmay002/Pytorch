{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b478cf50-aeb5-4d1f-982d-b3af4b0c1508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c7a68d8-f9d0-4815-a69e-c36c62002704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  If you decide to eat here, just be aware it is...    3.0\n",
       "1  I've taken a lot of spin classes over the year...    5.0\n",
       "2  Family diner. Had the buffet. Eclectic assortm...    3.0\n",
       "3  Wow!  Yummy, different,  delicious.   Our favo...    5.0\n",
       "4  Cute interior and owner (?) gave us tour of up...    4.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('yelp_review.csv').iloc[:20000,1:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "488d8f2c-23ee-4d8c-aa09-57a17ffee5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('yelp_review.csv').iloc[:20000,2:]\n",
    "df1.head()\n",
    "df['stars']=df1['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0adcdbaa-85e0-4cec-a6be-6fece71dfdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        if you decide to eat here, just be aware it is...\n",
       "1        i've taken a lot of spin classes over the year...\n",
       "2        family diner. had the buffet. eclectic assortm...\n",
       "3        wow! yummy, different, delicious. our favorite...\n",
       "4        cute interior and owner (?) gave us tour of up...\n",
       "                               ...                        \n",
       "19995    manager is a complete asshole. if you have a b...\n",
       "19996    if you're looking for bingo around st louis, t...\n",
       "19997    unfortunately we had a bad experience here...w...\n",
       "19998    meh. this pizza was basically a deep-dish grea...\n",
       "19999    this place is amazing. excellent sushi burrito...\n",
       "Name: cleaned, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def clean(text):\n",
    "    lst_of_tokens = [token.lower() for token in text.split() if token not in punctuation] \n",
    "    return ' '.join(lst_of_tokens)\n",
    "df['cleaned'] = df['text'].apply(clean)\n",
    "df['cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd3d186f-9ea3-410c-950a-48206a7ba195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 103760),\n",
       " ('and', 71159),\n",
       " ('a', 52976),\n",
       " ('i', 50885),\n",
       " ('to', 46224),\n",
       " ('was', 36817),\n",
       " ('of', 28959),\n",
       " ('is', 24808),\n",
       " ('for', 23454),\n",
       " ('in', 21873),\n",
       " ('it', 21221),\n",
       " ('my', 17874),\n",
       " ('we', 17211),\n",
       " ('with', 16441),\n",
       " ('but', 15711),\n",
       " ('this', 15467),\n",
       " ('that', 15317),\n",
       " ('they', 14789),\n",
       " ('on', 13662),\n",
       " ('you', 12934),\n",
       " ('have', 12302),\n",
       " ('had', 11911),\n",
       " ('were', 11522),\n",
       " ('not', 11508),\n",
       " ('are', 10143)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_text = ' '.join(df['cleaned'])\n",
    "# create a list of words\n",
    "words = all_text.split()\n",
    "# Count all the words using Counter Method\n",
    "count_words = Counter(words)\n",
    "\n",
    "total_words = len(words)\n",
    "sorted_words = count_words.most_common(total_words)\n",
    "sorted_words[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b425c03a-9d5d-4ab4-96aa-f61bdee70150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to create a vocab which contains int in sequence starting from index 1 , becasue we will have <pad> as 0\n",
    "\n",
    "vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab10ed55-b99d-476b-9b87-925ffa5e9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['encoded_lst'] = df['cleaned'].apply(lambda x: [vocab_to_int[token] for token in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eaf0e0c7-c916-4ee2-afc3-2062903ef464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars_enc'] = df['stars'].apply(lambda x:1.0 if x>4.0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5602db4-1a97-434d-9ea9-45143ef92523",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_encoded_lst  =[]\n",
    "for i in range(len(df)):\n",
    "    all_encoded_lst.append(df['encoded_lst'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f3d6b40-3d2f-47ab-9211-53a6899a914f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35,\n",
       "  20,\n",
       "  1471,\n",
       "  5,\n",
       "  151,\n",
       "  523,\n",
       "  38,\n",
       "  29,\n",
       "  2211,\n",
       "  11,\n",
       "  8,\n",
       "  120,\n",
       "  5,\n",
       "  130,\n",
       "  54,\n",
       "  184,\n",
       "  476,\n",
       "  44,\n",
       "  2927,\n",
       "  5,\n",
       "  3303,\n",
       "  13,\n",
       "  21,\n",
       "  174,\n",
       "  11,\n",
       "  992,\n",
       "  1223,\n",
       "  75,\n",
       "  4,\n",
       "  131,\n",
       "  5,\n",
       "  40,\n",
       "  581,\n",
       "  4,\n",
       "  21,\n",
       "  61,\n",
       "  5,\n",
       "  50,\n",
       "  76,\n",
       "  1925,\n",
       "  10,\n",
       "  6490,\n",
       "  2,\n",
       "  99,\n",
       "  22,\n",
       "  3,\n",
       "  219,\n",
       "  345,\n",
       "  1,\n",
       "  31,\n",
       "  8,\n",
       "  220,\n",
       "  15,\n",
       "  11,\n",
       "  785,\n",
       "  3,\n",
       "  30,\n",
       "  196,\n",
       "  59,\n",
       "  5,\n",
       "  107,\n",
       "  347,\n",
       "  1,\n",
       "  2239,\n",
       "  8,\n",
       "  30,\n",
       "  7723,\n",
       "  15,\n",
       "  299,\n",
       "  2240,\n",
       "  13,\n",
       "  21,\n",
       "  38,\n",
       "  22,\n",
       "  113,\n",
       "  146,\n",
       "  1472,\n",
       "  185,\n",
       "  13,\n",
       "  835,\n",
       "  136,\n",
       "  113,\n",
       "  196,\n",
       "  3021,\n",
       "  13,\n",
       "  299,\n",
       "  5403,\n",
       "  9,\n",
       "  163,\n",
       "  1572,\n",
       "  49,\n",
       "  114,\n",
       "  19,\n",
       "  1,\n",
       "  5404,\n",
       "  10,\n",
       "  102,\n",
       "  5,\n",
       "  29,\n",
       "  396,\n",
       "  16226]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_encoded_lst[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4e91966-6c3c-41a5-a86f-e350da9e28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(len_of_dataset,seq_length):\n",
    "\n",
    "    #len_of_dataset = df.shape[0]\n",
    "    #seq_length = 200\n",
    "\n",
    "    features = np.zeros((len_of_dataset,seq_length),dtype = int)    #20000,200\n",
    "    for i,text  in enumerate(all_encoded_lst):\n",
    "        #print(text)\n",
    "        text_len = len(text)\n",
    "\n",
    "        if text_len <= seq_length:\n",
    "            zeros_appended = list(np.zeros(seq_length-text_len))\n",
    "            new = zeros_appended + text\n",
    "        else:\n",
    "            new = text[:seq_length]\n",
    "        features[i,:]   = np.array(new)\n",
    "    #print(features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9999fa7c-35b2-4234-b510-1dcecce8ac48",
   "metadata": {},
   "source": [
    "<b>SPLIT THE DATA</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e838093-2998-4e41-837f-afee14bf1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features\n",
    "y = df['stars_enc']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,stratify=y,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80114040-96eb-4e20-be59-a59669557b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(x_train),torch.from_numpy(y_train.values))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test),torch.from_numpy(y_test.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0fd4f381-8097-4f23-9c1e-2b3ea274942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to SHUFFLE your data\n",
    "batch_size = 100\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2bc6bdd-3fcf-4a4f-a143-a710749b65ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([100, 200])\n",
      "Sample input: \n",
      " tensor([[   16,   435,     8,  ...,     8,  2081, 80343],\n",
      "        [    0,     0,     0,  ...,    28,     4, 34321],\n",
      "        [    0,     0,     0,  ...,    53,   240,   947],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,    33,   184,   872],\n",
      "        [    0,     0,     0,  ...,     1,    31,  1039],\n",
      "        [    0,     0,     0,  ...,   288,   130,   108]], dtype=torch.int32)\n",
      "\n",
      "Sample label size:  torch.Size([100])\n",
      "Sample label: \n",
      " tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 0., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c97d385d-b38a-4dfe-baf3-1ff36f943b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_length = 3\n",
    "hidden_dim = 4\n",
    "\n",
    "lstm_out = torch.randn(batch_size, seq_length, hidden_dim)\n",
    "print(lstm_out.size())  # output: torch.Size([2, 3, 4])\n",
    "\n",
    "print(lstm_out.contiguous().size())#contigius creates a copy and stores in diff mem loc , usefull for operations such as transposse, reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8db45604-2590-48c0-996c-699d81e0f54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7923, -1.3737, -0.4511,  0.8726],\n",
       "        [-0.9581, -0.9765,  0.0406,  0.1735],\n",
       "        [ 0.2002,  1.0429, -0.1244, -1.3146],\n",
       "        [-1.8264, -0.5591,  1.2189, -0.7296],\n",
       "        [-0.6415, -1.8003, -0.3025,  1.0516],\n",
       "        [ 0.0329,  2.8075,  0.2792, -0.7642]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out.view(-1,hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24774e-4ed6-4e3f-a546-d2de6783862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_out = lstm_out.contiguous().view(-1, hidden_dim)\n",
    "print(lstm_out.size())  # output: torch.Size([6, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "32486f3d-c9dc-4192-b9b7-ff63af742857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e414aae8-c258-4ae4-b26d-8b974665039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_yelp(nn.Module):\n",
    "    def __init__(self,vocab_size,emb_dim,hidden_dim,n_outputs,n_layer):\n",
    "        super().__init__()\n",
    "        #self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_outputs = n_outputs\n",
    "        self.n_layer= n_layer\n",
    "        self.embedding = nn.Embedding(vocab_size,emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim,self.hidden_dim,batch_first=True,num_layers=n_layer)\n",
    "        self.fc = nn.Linear(hidden_dim, self.n_outputs)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x,hidden)    :\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_output, hidden = self.lstm(embeds, hidden)\n",
    "\n",
    "        # stack up lstm outputs, for output to be fed in NN, it should have (batch*seq_length, hidden)\n",
    "        lstm_output = lstm_output.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(lstm_output)\n",
    "        sig_out = self.sig(out)\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]\n",
    "\n",
    "\n",
    "        \n",
    "        return sig_out,hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            hidden = (weight.new(self.n_layer, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layer, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layer, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layer, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "32663737-6a85-4c5d-a322-7b6ce67dabd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_yelp(\n",
      "  (embedding): Embedding(82700, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
    "n_outputs = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "batch_size = 100\n",
    "\n",
    "model = LSTM_yelp(vocab_size, embedding_dim,hidden_dim,n_outputs, n_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "16a7a5e1-acc5-4379-890b-af2b81ccfff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "h = model.init_hidden(batch_size)\n",
    "print(h[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "db033c4f-f80c-41d4-bc06-794f4854b146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([i.data for i in h ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "de4f6b23-ceca-4902-94b4-f46149ae31a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.577491... Val Loss: 0.575144\n",
      "Epoch: 2/4... Step: 200... Loss: 0.422333... Val Loss: 0.576997\n",
      "Epoch: 3/4... Step: 300... Loss: 0.179247... Val Loss: 0.621252\n",
      "Epoch: 3/4... Step: 400... Loss: 0.269241... Val Loss: 0.685635\n",
      "Epoch: 4/4... Step: 500... Loss: 0.198815... Val Loss: 0.771847\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# training params\n",
    "\n",
    "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(torch.cuda.is_available()):\n",
    "    model.cuda()\n",
    "\n",
    "model.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(torch.cuda.is_available()):\n",
    "            #print('True cuda is avualable')\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        inputs = inputs.type(torch.LongTensor).cuda()\n",
    "        \n",
    "        output, h = model(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inputs, labels in test_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(torch.cuda.is_available()):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                inputs = inputs.type(torch.LongTensor).cuda()\n",
    "                output, val_h = model(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1fff7191-94de-421c-9961-177a33185041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a56b6efa-0d36-433d-9f01-bd9e2728ca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16, 1800, 22, 1, 78, 7902, 2, 1, 6, 26, 36, 4, 242, 11]] 14\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 14 is out of bounds for axis 0 with size 14",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# test sequence padding\u001b[39;00m\n\u001b[0;32m     26\u001b[0m seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[1;32m---> 28\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_ints\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(features)\n",
      "Cell \u001b[1;32mIn[24], line 16\u001b[0m, in \u001b[0;36mpad_sequences\u001b[1;34m(len_of_dataset, seq_length)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     new \u001b[38;5;241m=\u001b[39m text[:seq_length]\n\u001b[1;32m---> 16\u001b[0m features[i,:]   \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(new)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 14 is out of bounds for axis 0 with size 14"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def tokenize_review(test_review):\n",
    "    test_review = test_review.lower() # lowercase\n",
    "    # get rid of punctuation\n",
    "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
    "\n",
    "    # splitting by spaces\n",
    "    test_words = test_text.split()\n",
    "\n",
    "    # tokens\n",
    "    test_ints = []\n",
    "    test_ints.append([vocab_to_int[word] for word in test_words])\n",
    "\n",
    "    return test_ints\n",
    "\n",
    "# test code and generate tokenized review\n",
    "\n",
    "test_review = 'This movie had the best acting and the was so good. I loved it.'\n",
    "\n",
    "test_ints = tokenize_review(test_review)\n",
    "print(test_ints,len(test_ints[0]))\n",
    "\n",
    "\n",
    "# test sequence padding\n",
    "seq_length=200\n",
    "\n",
    "features = pad_sequences(len(test_ints[0]), seq_length)\n",
    "\n",
    "print(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2a3374f8-bf61-4b83-b651-5c0bed57b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_review, sequence_length=200):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # tokenize review\n",
    "    test_ints = tokenize_review(test_review)\n",
    "    \n",
    "    # pad tokenized sequence\n",
    "    seq_length=sequence_length\n",
    "    features = pad_features(test_ints, seq_length)\n",
    "    \n",
    "    # convert to tensor to pass into your model\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "    \n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    # initialize hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "    \n",
    "    if(torch.cuda.is_available()):\n",
    "        feature_tensor = feature_tensor.cuda()\n",
    "    \n",
    "    # get the output from the model\n",
    "    output, h = model(feature_tensor, h)\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze()) \n",
    "    # printing output value, before rounding\n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "    \n",
    "    # print custom response\n",
    "    if(pred.item()==1):\n",
    "        print(\"Positive review detected!\")\n",
    "    else:\n",
    "        print(\"Negative review detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22cc700-4a17-4fd7-ab19-24692b5f43aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
