{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoVJW9nUjOyeE62IXXnpYF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmay002/Pytorch/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_LMF0eZ-l1ma"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re,json,string,os\n",
        "import collections\n",
        "from collections import Counter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features =2 \n",
        "hidden_dim =2\n",
        "torch.manual_seed(19)\n",
        "rnn_cell = nn.RNNCell(n_features,hidden_dim)\n",
        "rnn_state = rnn_cell.state_dict()\n",
        "rnn_state\n",
        "\n",
        "#weights ih and bias ih is for inputs vectors\n",
        "#weights hh and bh is for hidden stat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m5DoC1C97_v",
        "outputId": "088fcbbf-a68f-4674-c46b-9240df324015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_ih',\n",
              "              tensor([[ 0.6627, -0.4245],\n",
              "                      [ 0.5373,  0.2294]])),\n",
              "             ('weight_hh',\n",
              "              tensor([[-0.4015, -0.5385],\n",
              "                      [-0.1956, -0.6835]])),\n",
              "             ('bias_ih', tensor([0.4954, 0.6533])),\n",
              "             ('bias_hh', tensor([-0.3565, -0.2904]))])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_input = nn.Linear(n_features, hidden_dim)\n",
        "linear_hidden = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "with torch.no_grad():\n",
        "    linear_input.weight = nn.Parameter(rnn_state['weight_ih'])\n",
        "    linear_input.bias = nn.Parameter(rnn_state['bias_ih'])\n",
        "    linear_hidden.weight = nn.Parameter(rnn_state['weight_hh'])\n",
        "    linear_hidden.bias = nn.Parameter(rnn_state['bias_hh'])"
      ],
      "metadata": {
        "id": "cSkvkKNd_Q8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_hidden = torch.zeros(1,hidden_dim)\n",
        "initial_hidden"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIYstWrR-s2e",
        "outputId": "c74df88e-0fa4-493e-c2e6-eaec7a0cf8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th = linear_hidden(initial_hidden)\n",
        "th"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hbmlZt4-s9O",
        "outputId": "ab168182-6c2e-496c-f317-febda35baf25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3565, -0.2904]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.as_tensor([[ 1.0349,  0.9661],\n",
        "        [ 0.8055, -0.9169],\n",
        "        [-0.8251, -0.9499],\n",
        "        [-0.8670,  0.9342]])"
      ],
      "metadata": {
        "id": "O_EYSuIvAlB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tx = linear_input(X[:1])#get the first point \n",
        "tx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCUW9e3u-tAc",
        "outputId": "1a7ab9f7-58a2-44dc-809b-adb20cce2d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7712, 1.4310]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding tx+th \n",
        "torch.tanh(tx+th)\n",
        "#its an updated hidden state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OCOVgHOBLeG",
        "outputId": "9df41ccd-ce22-4b21-f2e2-d46302eaf64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3924, 0.8146]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets check this` in rnncell \n",
        "rnn_cell(X[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVi8IYJpBdjs",
        "outputId": "2a74e9b3-d7b8-4a14-d0b5-f3610ef373d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3924, 0.8146]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.arraylike import default_array_ufunc\n",
        "rnn_cell(X)\n",
        "#this is worg!!!!!!\n",
        "#why?\n",
        "#remember, rnn_cell has two inputs (inp and hidden). if hidden is not specified each time it \n",
        "#will take default as zero \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh1N3rIACFYH",
        "outputId": "06934dc4-4823-4bd8-890d-63f421495529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3924,  0.8146],\n",
              "        [ 0.7864,  0.5266],\n",
              "        [-0.0047, -0.2898],\n",
              "        [-0.6817,  0.1109]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#so we need to loop and provide updated hidden state at each timestep\n",
        "hidden = torch.zeros(1,hidden_dim)\n",
        "for i in range(X.shape[0]):\n",
        "  out = rnn_cell(X[i:i+1],hidden)\n",
        "  print(out)\n",
        "  hidden = out\n",
        "\n",
        "#the last state[[-0.5297,  0.3551]], is representation of full sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVeogPyECsWd",
        "outputId": "b20494c5-97e2-4d06-a2fe-aae1456933fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3924, 0.8146]], grad_fn=<TanhBackward0>)\n",
            "tensor([[ 0.4347, -0.0481]], grad_fn=<TanhBackward0>)\n",
            "tensor([[-0.1521, -0.3368]], grad_fn=<TanhBackward0>)\n",
            "tensor([[-0.5297,  0.3551]], grad_fn=<TanhBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shape and sizes of vectors**\n",
        "\n"
      ],
      "metadata": {
        "id": "GH4xfHe3EM0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input_shape**\n",
        "<li>default :(seq_len, bacth_size, n_of_feat)</li>\n",
        "<li>batch_first provide in (batch, seq_len, n_feat)</li>\n",
        "\n",
        "**hidden_state_Shape**\n",
        "<li>simple rnn hidden_state is (1 ,batch_size, hidd_dim)</li>\n",
        "<li>stacked RNN (n_stacked_layer, batch_size , hidd_dim)</li>\n",
        "<li>Bi_direction (2*n_stack_layer, batch_size, hidd_dim)</li>\n",
        "\n",
        "**Output_SHape**\n",
        "<li>simple : (seq_lem , batch_size , hidd_dim)</li>\n",
        "<li>Bi-Direction : (seq_len, batch_size, 2*hidd)</li>\n",
        "<li>btach_first : (batch_size, seq_len, hidd_dim)</li>"
      ],
      "metadata": {
        "id": "uNLeKnXxEYFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.randn(3, 4, 2)\n",
        "batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvzCM897CFeI",
        "outputId": "f5e35f7e-98aa-40bb-f7e2-e100a7ff0026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN uses seq first, we need to change it to batch first\n",
        "permute_batch = batch.permute(1,0,2)\n",
        "permute_batch.shape\n",
        "#now it is RNN friendly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No2nmokcCFhO",
        "outputId": "c1f623c1-796e-456e-e3f4-de93b8e2bb12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_cell = nn.RNN(input_size = 2,hidden_size = 2)\n",
        "out , final_hidden = rnn_cell(permute_batch) #applies tanh(wx+b)\n",
        "out.shape,final_hidden.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzB8GZ6FCFlK",
        "outputId": "dd7fe605-e132-4c05-e7c1-7d30becb0c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 3, 2]), torch.Size([1, 3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for simple rnn, last stage output is final output\n",
        "final_hidden"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i--xBh5eCFoW",
        "outputId": "d410e7e5-8eca-41fb-c8ee-52c1b604f64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3821,  0.5625],\n",
              "         [ 0.6310, -0.2361],\n",
              "         [ 0.8145,  0.7109]]], grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-0aRgsZJy07",
        "outputId": "95bc719f-5451-4536-c73f-b37f3f494e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3821,  0.5625],\n",
              "        [ 0.6310, -0.2361],\n",
              "        [ 0.8145,  0.7109]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(out[-1]==final_hidden).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhM3sc2eJy7A",
        "outputId": "1a4754b9-7bbb-48b2-a7d6-4b8c7c1cc057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#or we can keep batch first True\n",
        "rnn_batch_first = nn.RNN(2,2,batch_first=True)\n",
        "out,final_hidden = rnn_batch_first(batch)\n",
        "out.shape,final_hidden.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yW8f0DrJy-T",
        "outputId": "c0210622-b740-479f-9845-84f61dec583c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 4, 2]), torch.Size([1, 3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stacked RNN**\n",
        "output of rnn are fed to other rnns.\n",
        "layer 1 with rnn cell 1\n",
        "layer 0 with rnn cells 0\n",
        "\n"
      ],
      "metadata": {
        "id": "TD_aWGWxLnYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_stacked = nn.RNN(input_size = 2,hidden_size=2,num_layers=2, batch_first=True)\n",
        "state = rnn_stacked.state_dict()\n",
        "state\n",
        "#weights abd biases of layer l_0 and l_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8xFMA3NJzBj",
        "outputId": "9d91d7e8-276b-4221-b29d-58b450cd3fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_ih_l0',\n",
              "              tensor([[-0.0316, -0.6799],\n",
              "                      [-0.6724,  0.0982]])),\n",
              "             ('weight_hh_l0',\n",
              "              tensor([[ 0.2065,  0.3822],\n",
              "                      [ 0.4892, -0.0878]])),\n",
              "             ('bias_ih_l0', tensor([ 0.0165, -0.6195])),\n",
              "             ('bias_hh_l0', tensor([0.0245, 0.4649])),\n",
              "             ('weight_ih_l1',\n",
              "              tensor([[-0.2977,  0.4305],\n",
              "                      [-0.0030, -0.5329]])),\n",
              "             ('weight_hh_l1',\n",
              "              tensor([[ 0.0258, -0.6403],\n",
              "                      [ 0.1777,  0.2684]])),\n",
              "             ('bias_ih_l1', tensor([0.6674, 0.3733])),\n",
              "             ('bias_hh_l1', tensor([-0.2702,  0.4040]))])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_layer_0 = nn.RNN(input_size=2,hidden_size=2,batch_first =True)\n",
        "rnn_layer_1 = nn.RNN(input_size=2,hidden_size=2,batch_first =True)\n",
        "\n",
        "rnn_layer_0.load_state_dict(dict(list(state.items())[:4]))\n",
        "rnn_layer_0.load_state_dict(dict([(k[:-1]+'0',v) for k,v in list(state.items())[:4]]))\n",
        "#keeping the variable name same but different wieghts."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn2Mc48PJzEj",
        "outputId": "f0df3487-e94b-4bae-c5ec-0e6cd7fb4c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(1,4,2) #1 batch, 4 seq_len, 2 feat\n",
        "X = X[:1]\n",
        "out0,h0 = rnn_layer_0(X)\n",
        "out1,h1 = rnn_layer_1(out0)\n"
      ],
      "metadata": {
        "id": "NNQwGv2DQO6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out1,h0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHKETYNsQ5IC",
        "outputId": "6dcea2eb-6402-4054-9cfb-160537115de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.7609,  0.1250],\n",
              "          [ 0.1387,  0.0074],\n",
              "          [ 0.6237, -0.1651],\n",
              "          [ 0.2745, -0.1441]]], grad_fn=<TransposeBackward1>),\n",
              " tensor([[[ 0.7399, -0.2148]]], grad_fn=<StackBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out1,h1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tO0rxRlQ6vv",
        "outputId": "e1289e5f-0284-4367-b8cd-e54c7a57eb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.7609,  0.1250],\n",
              "          [ 0.1387,  0.0074],\n",
              "          [ 0.6237, -0.1651],\n",
              "          [ 0.2745, -0.1441]]], grad_fn=<TransposeBackward1>),\n",
              " tensor([[[ 0.2745, -0.1441]]], grad_fn=<StackBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out1,torch.cat([h0,h1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu3B2NDCQO-Q",
        "outputId": "b9d56d11-34de-4dde-e804-2651aad8e46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.7609,  0.1250],\n",
              "          [ 0.1387,  0.0074],\n",
              "          [ 0.6237, -0.1651],\n",
              "          [ 0.2745, -0.1441]]], grad_fn=<TransposeBackward1>),\n",
              " tensor([[[ 0.7399, -0.2148]],\n",
              " \n",
              "         [[ 0.2745, -0.1441]]], grad_fn=<CatBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cross cheeck\n",
        "out, hiddn = rnn_stacked(X)\n",
        "out,hiddn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gMIZEwgQPB3",
        "outputId": "5c4f98a0-46bd-4d1a-eeb2-89d4f3623011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.5626,  0.3755],\n",
              "          [-0.0507,  0.7475],\n",
              "          [-0.1235,  0.6402],\n",
              "          [-0.3173,  0.7777]]], grad_fn=<TransposeBackward1>),\n",
              " tensor([[[ 0.7399, -0.2148]],\n",
              " \n",
              "         [[-0.3173,  0.7777]]], grad_fn=<StackBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#simple rnn, final output elment is hidden state of last layer.\n",
        "#since its batch first, we need to make hidden stae dim to batch first as welll\n",
        "out[:,-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQiqs9ufQPLh",
        "outputId": "972dd7ec-941f-4467-dfa1-163b8cf063de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3173,  0.7777]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hiddn.permute(1,0,2)[:,-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS-haBbiRyzI",
        "outputId": "97d7af86-85b2-4700-b194-984487d50e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3173,  0.7777]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xi3S-pjTQPMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in list(state.items())[4:]:\n",
        "  print(k[:-1]+'0',v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp5WCb4cPBwN",
        "outputId": "4a396342-947b-439a-d836-4880ca2f906a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_ih_l0 tensor([[-0.2977,  0.4305],\n",
            "        [-0.0030, -0.5329]])\n",
            "weight_hh_l0 tensor([[ 0.0258, -0.6403],\n",
            "        [ 0.1777,  0.2684]])\n",
            "bias_ih_l0 tensor([0.6674, 0.3733])\n",
            "bias_hh_l0 tensor([-0.2702,  0.4040])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bidirectional RNN**\n",
        "<li>for one RNN we feed data in sequwnce of points and for another data we feed data in reverese order</li>\n",
        "\n",
        "<li>Unlike stacked RNN which uses its hidden states  as inpu to next RNN, bidrectiona; keeps hidden states of both layer </li>"
      ],
      "metadata": {
        "id": "WUPev5J0m4Zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(19)\n",
        "rnn_bidirect = nn.RNN(input_size=2,hidden_size = 2 , bidirectional= True , batch_first = True)\n",
        "state = rnn_bidirect.state_dict()\n",
        "state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqOksBxGmfQT",
        "outputId": "88aa86f5-1518-42b0-8221-747deaf16dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_ih_l0',\n",
              "              tensor([[ 0.6627, -0.4245],\n",
              "                      [ 0.5373,  0.2294]])),\n",
              "             ('weight_hh_l0',\n",
              "              tensor([[-0.4015, -0.5385],\n",
              "                      [-0.1956, -0.6835]])),\n",
              "             ('bias_ih_l0', tensor([0.4954, 0.6533])),\n",
              "             ('bias_hh_l0', tensor([-0.3565, -0.2904])),\n",
              "             ('weight_ih_l0_reverse',\n",
              "              tensor([[-0.6701, -0.5811],\n",
              "                      [-0.0170, -0.5856]])),\n",
              "             ('weight_hh_l0_reverse',\n",
              "              tensor([[ 0.1159, -0.6978],\n",
              "                      [ 0.3241, -0.0983]])),\n",
              "             ('bias_ih_l0_reverse', tensor([-0.3163, -0.2153])),\n",
              "             ('bias_hh_l0_reverse', tensor([ 0.0722, -0.3242]))])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in list(state.items())[4:]:\n",
        "  print(k[:-8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fLwO2tqq15",
        "outputId": "8c436f01-af6b-4e63-da6e-da5531c1a739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_ih_l0\n",
            "weight_hh_l0\n",
            "bias_ih_l0\n",
            "bias_hh_l0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_forward = nn.RNN(input_size=2,hidden_size=2,batch_first = True)\n",
        "rnn_reverse = nn.RNN(input_size = 2,hidden_size = 2, batch_first=True)\n",
        "\n",
        "rnn_forward.load_state_dict(dict(list(state.items())[:4]))\n",
        "rnn_reverse.load_state_dict( dict([(k[:-8],v)  for k, v in list(state.items())[4:]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4VnM468mfKi",
        "outputId": "b1bf1d07-f992-4172-8e30-5a8af54bd678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(1,4,2)\n"
      ],
      "metadata": {
        "id": "Nlw7URNxmfH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_rev = torch.flip(X,dims=[1])  #reverses the order of inputs"
      ],
      "metadata": {
        "id": "PbqsRJ-Hrd00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out,h = rnn_forward(X)\n",
        "out_rev,h_rev = rnn_reverse(X_rev)\n"
      ],
      "metadata": {
        "id": "rsKboeOfmfCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(out.shape,h.shape)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge6e6wQyme4c",
        "outputId": "9c55fe7f-593a-4f89-f5b5-fc1c37c6935e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 2]) torch.Size([1, 1, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6383,  0.3747],\n",
              "         [ 0.2004,  0.8140],\n",
              "         [-0.2374, -0.7248],\n",
              "         [ 0.7238,  0.8588]]], grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out_rev.shape,h_rev.shape)\n",
        "out_rev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPz-H2uhmev4",
        "outputId": "46490f8a-9f8e-47ec-9106-601a45e159a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 2]) torch.Size([1, 1, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6636, -0.6050],\n",
              "         [ 0.8776,  0.1293],\n",
              "         [-0.9676, -0.7794],\n",
              "         [ 0.3715, -0.2956]]], grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_rev_back = torch.flip(out_rev,dims =[1])"
      ],
      "metadata": {
        "id": "cEMaY-kumetu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat([out,out_rev_back],dim=2),torch.cat([h,h_rev])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_qCV5GOmems",
        "outputId": "af5a8d1d-4e2b-42ba-a6ea-c24f3b70e3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.6383,  0.3747,  0.3715, -0.2956],\n",
              "          [ 0.2004,  0.8140, -0.9676, -0.7794],\n",
              "          [-0.2374, -0.7248,  0.8776,  0.1293],\n",
              "          [ 0.7238,  0.8588, -0.6636, -0.6050]]], grad_fn=<CatBackward0>),\n",
              " tensor([[[ 0.7238,  0.8588]],\n",
              " \n",
              "         [[ 0.3715, -0.2956]]], grad_fn=<CatBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out,hidden = rnn_bidirect(X)\n",
        "out,hidden "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtdaueLgmehF",
        "outputId": "d4dc6afb-74db-41ec-bb60-9466cfd448ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.6383,  0.3747,  0.3715, -0.2956],\n",
              "          [ 0.2004,  0.8140, -0.9676, -0.7794],\n",
              "          [-0.2374, -0.7248,  0.8776,  0.1293],\n",
              "          [ 0.7238,  0.8588, -0.6636, -0.6050]]], grad_fn=<TransposeBackward1>),\n",
              " tensor([[[ 0.7238,  0.8588]],\n",
              " \n",
              "         [[ 0.3715, -0.2956]]], grad_fn=<StackBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#in BIdredt last state of output is not final hidden state\n",
        "#make hidden state dim to batch_first\n",
        "\n",
        "hidden.permute(1,0,2).view(1,-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ejVDLD-meau",
        "outputId": "06e32bbe-0e83-4214-8bc0-f66b6099280e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7238,  0.8588,  0.3715, -0.2956]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRU**"
      ],
      "metadata": {
        "id": "rxgNtl6YE6Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_features =2\n",
        "n_dim = 2\n",
        "torch.manual_seed(17)\n",
        "gru_cell = nn.GRUCell(input_size=n_features,hidden_size = n_dim)\n",
        "gru_state = gru_cell.state_dict()\n",
        "gru_state\n",
        "\n",
        "#n,z,k are all concatenated in Weight matirx and each of them have sixe of n_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3wi34dCmeTK",
        "outputId": "73adf6ae-609a-4153-8e41-cf9307a3ea36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_ih',\n",
              "              tensor([[-0.0930,  0.0497],\n",
              "                      [ 0.4670, -0.5319],\n",
              "                      [-0.6656,  0.0699],\n",
              "                      [-0.1662,  0.0654],\n",
              "                      [-0.0449, -0.6828],\n",
              "                      [-0.6769, -0.1889]])),\n",
              "             ('weight_hh',\n",
              "              tensor([[-0.4167, -0.4352],\n",
              "                      [-0.2060, -0.3989],\n",
              "                      [-0.7070, -0.5083],\n",
              "                      [ 0.1418,  0.0930],\n",
              "                      [-0.5729, -0.5700],\n",
              "                      [-0.1818, -0.6691]])),\n",
              "             ('bias_ih',\n",
              "              tensor([-0.4316,  0.4019,  0.1222, -0.4647, -0.5578,  0.4493])),\n",
              "             ('bias_hh',\n",
              "              tensor([-0.6800,  0.4422, -0.3559, -0.0279,  0.6553,  0.2918]))])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Wx,bx = gru_state['weight_ih'],gru_state['bias_ih']\n",
        "Wh,bh = gru_state['weight_hh'],gru_state['bias_hh']"
      ],
      "metadata": {
        "id": "MSBdkx2zmd-_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'input shape {Wx.shape} {bx.shape}')\n",
        "print(f'input shape {Wh.shape} {bh.shape}')"
      ],
      "metadata": {
        "id": "V3XnB5TeF4Ck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59d4144-ca6b-4d88-d93d-3ef3b04d5d87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape torch.Size([6, 2]) torch.Size([6])\n",
            "input shape torch.Size([6, 2]) torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Wxr,Wxz,Wxn = Wx.split(2)\n",
        "bxr,bxz,bxn = bx.split(2)\n",
        "\n",
        "Whr,Whz,Whn = Wh.split(2)\n",
        "bhr,bhz,bhn = bh.split(2)"
      ],
      "metadata": {
        "id": "SMCXMlxdF4Gh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Wx.size()"
      ],
      "metadata": {
        "id": "JuCjCNR1F4KB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcca8773-e712-4297-879e-aa91979ea422"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_layer(Wx,bx,Wh,bh):\n",
        "  hidden_dim , n_feat = Wx.size()#(2,2)\n",
        "  lin_input = nn.Linear(n_feat,hidden_dim)\n",
        "  lin_input.load_state_dict({'weight':Wx,'bias':bx})\n",
        "  lin_hidden = nn.Linear(hidden_dim,hidden_dim)\n",
        "  lin_hidden.load_state_dict({'weight':Wh,'bias':bh})\n",
        "\n",
        "  return lin_hidden,lin_input"
      ],
      "metadata": {
        "id": "qyHHbAOTF4NN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_hidden,r_input = linear_layer(Wxr,bxr,Whr,bhr)\n",
        "z_hidden,z_input = linear_layer(Wxz,bxz,Whz,bhz)\n",
        "n_hidden,n_input = linear_layer(Wxn,bxn,Whn,bhn)\n"
      ],
      "metadata": {
        "id": "EnDbm8VvF4QO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_gate(h,x):\n",
        "  thr = r_hidden(x)\n",
        "  txr = r_input(x)\n",
        "  r = torch.sigmoid(thr+txr)\n",
        "  return r\n",
        "\n",
        "def update_gate(h,x):\n",
        "  thz = z_hidden(x)\n",
        "  txz = z_input(x)\n",
        "  z = torch.sigmoid(thz+txz)\n",
        "  return z\n",
        "\n",
        "def candidate_n(h,x,r):\n",
        "  thn = n_hidden(x)\n",
        "  txn = n_input(x)\n",
        "  n = torch.sigmoid( r * thn + txn)\n",
        "  return n    "
      ],
      "metadata": {
        "id": "UlU9OUoYF4TO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_hidden_state = torch.zeros(1,n_dim)\n",
        "X = torch.as_tensor([[ 1.0349,  0.9661]])\n",
        "r = reset_gate(initial_hidden_state,X)\n",
        "r"
      ],
      "metadata": {
        "id": "-df2fbsAF4WI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24fcc42f-49eb-4a0c-ecfc-c8361a8dd7c5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1180, 0.5535]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rest_gate is input ot candidtae \n",
        "n = candidate_n(initial_hidden_state,X,r)\n",
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neh5e41jL5jE",
        "outputId": "31129336-6a67-4492-ad12-8f9a2dabb53f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2106, 0.3243]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z =update_gate(initial_hidden_state,X)\n",
        "z\n",
        "#update gate is telling to keep 11% and 41% of in initla_hidden_stae and remaining is coming from candidiate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpUyj8PkL5nL",
        "outputId": "5f8735e9-fcca-40a5-e9bb-310e91589ea0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1113, 0.4098]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_prime = n*(1-z)+initial_hidden_state*z\n",
        "h_prime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfTU9AkmL5q7",
        "outputId": "dcf65a9c-beac-4e2b-f301-2453a5f6e403"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1871, 0.1914]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_cell(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWUO8Ng5L5ut",
        "outputId": "524f2b96-89a9-4947-f649-cf151ef69091"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5635, -0.1470]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8EI6elUEL5yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "twa5W8RiL51n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElmanRNN(nn.Module):\n",
        "\n",
        "  def __intit__(self,input_size,hidden_size,batch_first = False):\n",
        "    super(ElmanRNN,self).__init__()\n",
        "    self.rnn_cell = nn.RNNCell(input_size=input_size,hidden_size = hidden_size)\n",
        "\n",
        "    self.batch_first = batch_first\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "  def _initialize_hidden(self,batch_size)  :\n",
        "    return torch.zeros((batch_size,self.hidden_size))\n",
        "\n",
        "  def forward(self,x_in,initial_hidden = None):\n",
        "    '''\n",
        "    Args :\n",
        "    x_in : if self.batch_first:\n",
        "          x_in.shape will be (batch, seq_size, feat_size)\n",
        "     else:         X_in.shape (seq_size,batch_size,feat_size)\n",
        "     Return:\n",
        "     hiiden vectors; output of RNN at each timestep\n",
        "       if self.bacth_first : shape will be (batch_size, seq_size, hidden_size)\n",
        "                      else, hidden.shape = (seq_size,batch_size,hidden_size)            \n",
        "    '''\n",
        "    if self.batch_first:\n",
        "      batch_size ,seq_size,feat_size = x_in.shape()\n",
        "      x_in = x_in.permute(1,0,2)\n",
        "    else:\n",
        "      seq_size,batch_size,feat_size = x_in.size()\n",
        "\n",
        "    hiddens = []\n",
        "\n",
        "    if initial_hidden is None:  \n",
        "      initial_hidden = self._initialize_hidden(batch_size)\n",
        "      initial_hidden = initial_hidden.to(x_in.device)\n",
        "\n",
        "    for t in range(seq_size)  :\n",
        "      hidden_t = self.rnn_cell(x_in[t],hidden_t)\n",
        "      hiddens.append(hidden_t)\n",
        "\n",
        "    hiddens = torch.stack(hiddens) \n",
        "\n",
        "    if self.batch_first :\n",
        "      hidden = hiddens.permute(1,0,2)\n",
        "\n",
        "    return hiddens   "
      ],
      "metadata": {
        "id": "EZT_qvDe5PZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O8Biyk7k5PQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mk_vwMcA5PI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_H85dnqe5O0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SurnameDataset(Dataset):\n",
        "    def __init__(self, surname_df, vectorizer):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            surname_df (pandas.DataFrame): the dataset\n",
        "            vectorizer (SurnameVectorizer): vectorizer instatiated from dataset\n",
        "        \"\"\"\n",
        "        self.surname_df = surname_df\n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        self.train_df = self.surname_df[self.surname_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.surname_df[self.surname_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.surname_df[self.surname_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
        "                             'val': (self.val_df, self.validation_size),\n",
        "                             'test': (self.test_df, self.test_size)}\n",
        "\n",
        "        self.set_split('train')\n",
        "        \n",
        "        # Class weights\n",
        "        class_counts = surname_df.nationality.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self._vectorizer.nationality_vocab.lookup_token(item[0])\n",
        "        \n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, surname_csv):\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
        "        \n",
        "        Args:\n",
        "            surname_csv (str): location of the dataset\n",
        "        Returns:\n",
        "            an instance of SurnameDataset\n",
        "        \"\"\"\n",
        "        surname_df = pd.read_csv(surname_csv)\n",
        "        train_surname_df = surname_df[surname_df.split=='train']\n",
        "        return cls(surname_df, SurnameVectorizer.from_dataframe(train_surname_df))\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, surname_csv, vectorizer_filepath):\n",
        "        \"\"\"Load dataset and the corresponding vectorizer. \n",
        "        Used in the case in the vectorizer has been cached for re-use\n",
        "        \n",
        "        Args:\n",
        "            surname_csv (str): location of the dataset\n",
        "            vectorizer_filepath (str): location of the saved vectorizer\n",
        "        Returns:\n",
        "            an instance of SurnameDataset\n",
        "        \"\"\"\n",
        "        surname_df = pd.read_csv(surname_csv)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(surname_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"a static method for loading the vectorizer from file\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
        "        Returns:\n",
        "            an instance of SurnameVectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return SurnameVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"saves the vectorizer to disk using json\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" returns the vectorizer \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        \n",
        "        Args:\n",
        "            index (int): the index to the data point \n",
        "        Returns:\n",
        "            a dictionary holding the data point's:\n",
        "                features (x_surname)\n",
        "                label (y_nationality)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "\n",
        "        surname_vector = self._vectorizer.vectorize(row.surname) #this  goes to SurVect Class\n",
        "        print(f'vectorzied surname of {row.surname} --> {surname_vector}')\n",
        "\n",
        "        nationality_index = self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
        "\n",
        "        return {'x_surname': surname_vector,\n",
        "                'y_nationality': nationality_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size\n",
        "\n",
        "    \n",
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"): \n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ],
      "metadata": {
        "id": "rS-7kvqxzplN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary(object):\n",
        "  \n",
        "  def __init__(self,token_to_idx=None):\n",
        "    \n",
        "    if token_to_idx is None:\n",
        "      token_to_idx = {}\n",
        "\n",
        "    self._token_to_idx = token_to_idx\n",
        "    self._idx_to_token = {v:k for k,v in self._token_to_idx.items()}\n",
        "    \n",
        "    # self._add_unk = add_unk\n",
        "    # self._unk_token = unk_token\n",
        "    # self._mask_token = mask_token\n",
        "    \n",
        "    # self._mask_index = self.add_token(self._mask_token)\n",
        "\n",
        "    # self.unk_index = -1\n",
        "    # if add_unk:\n",
        "    #   self.unk_index = self.add_token(unk_token)\n",
        "    \n",
        "\n",
        "  def add_token(self,token):\n",
        "    '''\n",
        "      add a token to dic torkn_to_idx\n",
        "\n",
        "    '''\n",
        "    if token in self._token_to_idx:\n",
        "      index = self._token_to_idx[token]\n",
        "\n",
        "    else:\n",
        "      index = len(self._token_to_idx) \n",
        "      self._idx_to_token[index] = token\n",
        "      self._token_to_idx[token] = index \n",
        "\n",
        "    return index\n",
        "\n",
        "  def lookup_token(self,token):\n",
        "    '''\n",
        "    get the index of the token\n",
        "    else, get the unk index if token not present\n",
        "    '''  \n",
        "    # if self._unk_index >=0:\n",
        "    #   return self._token_to_idx.get(token,self._unk_index)\n",
        "    # else:\n",
        "    return self._token_to_idx[token]  \n",
        " \n",
        "  def lookup_index(self, index):\n",
        "    \"\"\"Return the token associated with the index\n",
        "    \n",
        "    Args: \n",
        "        index (int): the index to look up\n",
        "    Returns:\n",
        "        token (str): the token corresponding to the index\n",
        "    Raises:\n",
        "        KeyError: if the index is not in the Vocabulary\n",
        "    \"\"\"\n",
        "    if index not in self._idx_to_token:\n",
        "        raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "    return self._idx_to_token[index]   \\\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self._token_to_idx)\n",
        "  \n",
        "  def __str__(self):\n",
        "    return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "  def to_serializable(self):\n",
        "    \"\"\" returns a dictionary that can be serialized \"\"\"\n",
        "    return {'token_to_idx': self._token_to_idx}\n",
        "\n",
        "  @classmethod\n",
        "  def from_serializable(cls, contents):\n",
        "    \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
        "    return cls(**contents)  \n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "nxnEqllRzpo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "  def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                 end_seq_token=\"<END>\"):\n",
        "\n",
        "    \n",
        "    super(SequenceVocabulary, self).__init__(token_to_idx) #super retunr obj of calss vocabulary\n",
        "    #and Vocab class is called with token_to_idx param\n",
        "\n",
        "    self._mask_token = mask_token  #its padding \n",
        "    self._unk_token = unk_token\n",
        "    self._begin_seq_token = begin_seq_token\n",
        "    self._end_seq_token = end_seq_token\n",
        "\n",
        "    self.mask_index = self.add_token(self._mask_token)\n",
        "    self.unk_index = self.add_token(self._unk_token)\n",
        "    self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
        "    self.end_seq_index = self.add_token(self._end_seq_token)\n",
        "\n",
        "  def to_serializable(self):\n",
        "    contents = super(SequenceVocabulary, self).to_serializable()\n",
        "    contents.update({'unk_token': self._unk_token,\n",
        "                      'mask_token': self._mask_token,\n",
        "                      'begin_seq_token': self._begin_seq_token,\n",
        "                      'end_seq_token': self._end_seq_token})\n",
        "    return contents\n",
        "\n",
        "  def lookup_token(self, token):\n",
        "    \"\"\"Retrieve the index associated with the token \n",
        "      or the UNK index if token isn't present.\n",
        "    \n",
        "    Args:\n",
        "        token (str): the token to look up \n",
        "    Returns:\n",
        "        index (int): the index corresponding to the token\n",
        "    Notes:\n",
        "        `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
        "          for the UNK functionality \n",
        "    \"\"\"\n",
        "    if self.unk_index >= 0:\n",
        "        return self._token_to_idx.get(token, self.unk_index)\n",
        "    else:\n",
        "        return self._token_to_idx[token]\n"
      ],
      "metadata": {
        "id": "rsCURq0B00m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SurnameVectorizer(object):\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
        "    def __init__(self, surname_vocab, nationality_vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            surname_vocab (Vocabulary): maps characters to integers\n",
        "            nationality_vocab (Vocabulary): maps nationalities to integers\n",
        "        \"\"\"\n",
        "        self.surname_vocab = surname_vocab\n",
        "        self.nationality_vocab = nationality_vocab\n",
        "        print(f'surname_vocab length {len(self.surname_vocab)}')\n",
        "        print(f'nationality_vocab length {len(self.nationality_vocab)}')\n",
        "\n",
        "    def vectorize(self, surname):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            surname (str): the surname\n",
        "\n",
        "        Returns:\n",
        "            one_hot (np.ndarray): a collapsed one-hot encoding \n",
        "        \"\"\"\n",
        "        vocab = self.surname_vocab    #{....} 80 key value pair\n",
        "        one_hot = np.zeros(len(vocab), dtype=np.float32) #len is 80 [0,0,0,0,....]\n",
        "        for token in surname:  # Macfauuen\n",
        "            print(f'printitng vectorize token {token}')\n",
        "            one_hot[vocab.lookup_token(token)] = 1\n",
        "\n",
        "        return one_hot #returned to DataSet class\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, surname_df):\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
        "        \n",
        "        Args:\n",
        "            surname_df (pandas.DataFrame): the surnames dataset\n",
        "        Returns:\n",
        "            an instance of the SurnameVectorizer\n",
        "        \"\"\"\n",
        "        surname_vocab = Vocabulary(unk_token=\"@\")\n",
        "        nationality_vocab = Vocabulary(add_unk=False)\n",
        "\n",
        "        for index, row in surname_df.iterrows():\n",
        "            print(f'printing index, row in {row.surname} {row.nationality}')\n",
        "            for letter in row.surname:\n",
        "                surname_vocab.add_token(letter)\n",
        "            nationality_vocab.add_token(row.nationality)\n",
        "\n",
        "        return cls(surname_vocab, nationality_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        surname_vocab = Vocabulary.from_serializable(contents['surname_vocab'])\n",
        "        nationality_vocab =  Vocabulary.from_serializable(contents['nationality_vocab'])\n",
        "        return cls(surname_vocab=surname_vocab, nationality_vocab=nationality_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'surname_vocab': self.surname_vocab.to_serializable(),\n",
        "                'nationality_vocab': self.nationality_vocab.to_serializable()}"
      ],
      "metadata": {
        "id": "7iUpCLX_z7JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XemjSrsDz7Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymZ2jPgKz7dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"Handle the training state updates.\n",
        "\n",
        "    Components:\n",
        "     - Early Stopping: Prevent overfitting.\n",
        "     - Model Checkpoint: Model is saved if the model is better\n",
        "\n",
        "    :param args: main arguments\n",
        "    :param model: model to train\n",
        "    :param train_state: a dictionary representing the training state values\n",
        "    :returns:\n",
        "        a new train_state\n",
        "    \"\"\"\n",
        "\n",
        "    # Save one model at least\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # Save model if performance improved\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "\n",
        "        # If loss worsened\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\n",
        "            # Update step\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # Loss decreased\n",
        "        else:\n",
        "            # Save the best model\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "\n",
        "            # Reset early stopping step\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # Stop early ?\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def compute_accuracy(y_pred, y_target):\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ],
      "metadata": {
        "id": "WQ54Sy1mz7g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "args = Namespace(\n",
        "    #@ Data and path Information:\n",
        "    surname_csv = 'surname_splits.csv',\n",
        "    vectorizer_file = \"vectorizer.json\",\n",
        "    model_state_file = \"model.pth\",\n",
        "    save_dir = \"model_storage/surname_mlp\",\n",
        "    #@ Model Hyperparameters:\n",
        "    hidden_dim = 100,\n",
        "    #@ Training Hyperparameters:\n",
        "    seed = 42,\n",
        "    num_epochs = 5,\n",
        "    early_stopping_criteria = 5,\n",
        "    learning_rate = 0.001,\n",
        "    batch_size = 128,\n",
        "    #@ Runtime Options:\n",
        "    cuda = True,\n",
        "    reload_from_files = False,\n",
        "    expand_filepaths_to_save_dir = True\n",
        ")\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
        "    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
        "    print(\"Expanded Filepaths: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "\n",
        "#@ Checking the CUDA:\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "#@ Set seed for Reproducibility:\n",
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "\n",
        "#@ Handle dirs:\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)\n",
        "handle_dirs(args.save_dir)\n"
      ],
      "metadata": {
        "id": "yPyC7jjC0DAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if args.reload_from_files:\n",
        "    # training from a checkpoint\n",
        "    print(\"Reloading!\")\n",
        "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv,\n",
        "                                                              args.vectorizer_file)\n",
        "else:\n",
        "    # create dataset and vectorizer\n",
        "    print(\"Creating fresh!\")\n",
        "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "    \n",
        "vectorizer = dataset.get_vectorizer()\n",
        "classifier = SurnameClassifier(input_dim = len(vectorizer.surname_vocab),   #80\n",
        "                               hid_dim = args.hidden_dim,                   #300\n",
        "                               out_dim= len(vectorizer.nationality_vocab))  #18\n",
        "\n",
        "#our vocab has 80 uniqye character with their index in dic form and nationality has 18 unique "
      ],
      "metadata": {
        "id": "cnjNBoxX0GCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate, weight_decay= 0.01)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                 mode='min', factor=0.5,\n",
        "                                                 patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "import time as t\n",
        "t1 = t.perf_counter()\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "\n",
        "        # Record the tarining stage\n",
        "        if (epoch_index+1) % 10 == 0:\n",
        "            print(\"Epoch [{}/{}]\".format(epoch_index+1, args.num_epochs))\n",
        "        \n",
        "        train_state['epoch_index'] = epoch_index\n",
        "        \n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------\n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = classifier(batch_dict['x_surname'])  #goes to get item and picks\n",
        "            print(f'y_pred {y_pred.shape}')\n",
        "            print(batch_dict['y_nationality'])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
        "            print(f'loss {loss}')\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # compute the output\n",
        "            y_pred =  classifier(batch_dict['x_surname'])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
        "            loss_t = loss.to(\"cpu\").item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        \n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")\n",
        "\n",
        "print('-----')\n",
        "t2 = t.perf_counter()\n",
        "print(\"Running time = {:.2f}\".format(t2-t1))"
      ],
      "metadata": {
        "id": "T8vsvCQ80KD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred =  classifier(batch_dict['x_surname'])\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ],
      "metadata": {
        "id": "jh8gOZKM0OBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_nationality(surname, classifier, vectorizer):\n",
        "    \"\"\"Predict the nationality from a new surname\n",
        "    \n",
        "    Args:\n",
        "        surname (str): the surname to classifier\n",
        "        classifier (SurnameClassifer): an instance of the classifier\n",
        "        vectorizer (SurnameVectorizer): the corresponding vectorizer\n",
        "    Returns:\n",
        "        a dictionary with the most likely nationality and its probability\n",
        "    \"\"\"\n",
        "    vectorized_surname = vectorizer.vectorize(surname)\n",
        "    print(f' vectorized surname {vectorized_surname}')\n",
        "    vectorized_surname = torch.tensor(vectorized_surname).unsqueeze(0)\n",
        "    print(vectorized_surname)\n",
        "    result = classifier(vectorized_surname, apply_softmax=True)\n",
        "    print(result.max(dim=1))\n",
        "    probability_values, indices = result.max(dim=1)\n",
        "    index = indices.item()\n",
        "\n",
        "    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
        "    probability_value = probability_values.item()\n",
        "\n",
        "    return {'nationality': predicted_nationality, 'probability': probability_value}"
      ],
      "metadata": {
        "id": "eYNo9mUe0RgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b0SWhSOv0OLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h5YuqXqs0OP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ndPIoD20OTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ooPshi920KIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-cz34HSF0KMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7joxYeYW0KPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "id": "VPyfqoDO0DGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0bdx8Iez7ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qg0dpaSsz7mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CrzIfTDgzpsO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}